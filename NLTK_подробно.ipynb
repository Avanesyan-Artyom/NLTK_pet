{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Анализ тональности текста на NLTK\n",
        "\n",
        "Это проект по анализу тональности. Он показывает несколько подходов: готовый лексикон VADER, классификацию субъективности и модель полярности на корпусе `movie_reviews`.\n",
        "\n",
        "**Что внутри:**\n",
        "- Быстрый baseline через VADER.\n",
        "- Субъективность (objective vs subjective) на корпусе `subjectivity`.\n",
        "- Полярность (positive vs negative) на корпусе `movie_reviews`.\n",
        "- Мини-выводы и идеи для развития проекта.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Установка и подготовка окружения\n",
        "\n",
        "Сначала потребуется скачать датасеты NLTK.\n",
        "\n",
        "```bash\n",
        "pip install nltk\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, subjectivity, movie_reviews\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import extract_unigram_feats, mark_negation\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('subjectivity')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Baseline: готовый лексикон VADER\n",
        "\n",
        "VADER — быстрый метод, который оценивает тональность без обучения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"Обожаю этот курс, он очень полезный и понятный!\",\n",
        "    \"Сервис работал ужасно, всё зависало и было медленно.\",\n",
        "    \"Фильм оказался неплохим, но ожидал большего.\",\n",
        "]\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "for text in texts:\n",
        "    scores = sia.polarity_scores(text)\n",
        "    print(text)\n",
        "    print(scores)\n",
        "    print('-' * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Субъективность: обучаемый классификатор\n",
        "\n",
        "Используем корпус `subjectivity`, где тексты помечены как `subj` (субъективные) и `obj` (объективные).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')]\n",
        "documents = subj_docs + obj_docs\n",
        "random.shuffle(documents)\n",
        "\n",
        "all_words = nltk.FreqDist(word.lower() for word in subjectivity.words())\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def subjectivity_features(doc):\n",
        "    doc = mark_negation(doc)\n",
        "    return extract_unigram_feats(doc, word_features)\n",
        "\n",
        "featuresets = [(subjectivity_features(d), c) for (d, c) in documents]\n",
        "train_set = featuresets[:1600]\n",
        "test_set = featuresets[1600:]\n",
        "\n",
        "subj_classifier = NaiveBayesClassifier.train(train_set)\n",
        "print('Accuracy:', accuracy(subj_classifier, test_set))\n",
        "subj_classifier.show_most_informative_features(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Полярность: классификация отзывов (movie_reviews)\n",
        "\n",
        "Построим собственный классификатор для позитивных/негативных отзывов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def to_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    if tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    if tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    if tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    return wordnet.NOUN\n",
        "\n",
        "def normalize(text):\n",
        "    tokens = [t.lower() for t in word_tokenize(text) if t.isalpha()]\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    return [lemmatizer.lemmatize(word, to_wordnet_pos(tag)) for word, tag in tagged]\n",
        "\n",
        "documents = []\n",
        "for category in movie_reviews.categories():\n",
        "    for fileid in movie_reviews.fileids(category):\n",
        "        words = normalize(movie_reviews.raw(fileid))\n",
        "        documents.append((words, category))\n",
        "\n",
        "random.shuffle(documents)\n",
        "\n",
        "all_words = nltk.FreqDist(word for words, _ in documents for word in words)\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def document_features(document_words):\n",
        "    document_words = set(document_words)\n",
        "    return {f'contains({word})': (word in document_words) for word in word_features}\n",
        "\n",
        "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
        "train_set = featuresets[:1500]\n",
        "test_set = featuresets[1500:]\n",
        "\n",
        "polarity_classifier = NaiveBayesClassifier.train(train_set)\n",
        "print('Accuracy:', accuracy(polarity_classifier, test_set))\n",
        "polarity_classifier.show_most_informative_features(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Применение модели к новым текстам\n",
        "\n",
        "Ниже — пример, как использовать обученный классификатор на новых отзывах.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = [\n",
        "    \"This movie is a masterpiece with brilliant acting.\",\n",
        "    \"The plot is boring and the pacing is terrible.\",\n",
        "]\n",
        "\n",
        "for text in samples:\n",
        "    words = normalize(text)\n",
        "    prediction = polarity_classifier.classify(document_features(words))\n",
        "    print(text)\n",
        "    print('Prediction:', prediction)\n",
        "    print('-' * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Итоги\n",
        "\n",
        "- **VADER** отлично подходит для быстрых оценок без обучения.\n",
        "- **Naive Bayes + `subjectivity`** позволяет определять субъективность.\n",
        "- **Movie Reviews** — пример полноценной пайплайн-модели: очистка, лемматизация, обучение.\n",
        "\n",
        "### Идеи для развития\n",
        "- Добавить TF-IDF или word embeddings.\n",
        "- Попробовать SVM/Logistic Regression.\n",
        "- Подключить визуализацию метрик (confusion matrix).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
